{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2236708,"sourceType":"datasetVersion","datasetId":1343913}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nimport sys\nimport argparse\nimport matplotlib.pyplot as plt\nplt.rcParams[\"axes.grid\"] = False\nimport matplotlib.image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport os\nimport gzip\nimport struct\nimport array\nfrom urllib.request import urlretrieve\nfrom torch.distributions.multivariate_normal import MultivariateNormal\nimport torch\nfrom torch.utils.data import Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-21T08:16:18.097031Z","iopub.execute_input":"2024-04-21T08:16:18.097823Z","iopub.status.idle":"2024-04-21T08:16:25.668682Z","shell.execute_reply.started":"2024-04-21T08:16:18.097781Z","shell.execute_reply":"2024-04-21T08:16:25.667411Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((150, 150)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((150, 150)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:16:25.670868Z","iopub.execute_input":"2024-04-21T08:16:25.671745Z","iopub.status.idle":"2024-04-21T08:16:25.678839Z","shell.execute_reply.started":"2024-04-21T08:16:25.671709Z","shell.execute_reply":"2024-04-21T08:16:25.677725Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Loading the data","metadata":{}},{"cell_type":"code","source":"dataset = datasets.ImageFolder('/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/', transform=train_transform)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T04:07:50.323923Z","iopub.execute_input":"2024-04-21T04:07:50.324360Z","iopub.status.idle":"2024-04-21T04:08:20.832494Z","shell.execute_reply.started":"2024-04-21T04:07:50.324323Z","shell.execute_reply":"2024-04-21T04:08:20.831226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# Apply validation transform to the validation dataset\nval_dataset.dataset.transform = val_transform\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T04:08:29.228441Z","iopub.execute_input":"2024-04-21T04:08:29.229090Z","iopub.status.idle":"2024-04-21T04:08:29.261167Z","shell.execute_reply.started":"2024-04-21T04:08:29.229056Z","shell.execute_reply":"2024-04-21T04:08:29.259952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=True, num_workers=4)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T04:08:43.716000Z","iopub.execute_input":"2024-04-21T04:08:43.716415Z","iopub.status.idle":"2024-04-21T04:08:43.727605Z","shell.execute_reply.started":"2024-04-21T04:08:43.716380Z","shell.execute_reply":"2024-04-21T04:08:43.725763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nfrom torch.distributions.multivariate_normal import MultivariateNormal\nfrom torch.optim import Adam\nimport torch.nn.functional as F\n\ndef array_to_image(array):\n    return np.reshape(np.array(array), [28, 28])\n\ndef concat_images(images, row, col, padding=3):\n    result = np.zeros((28 * row + (row - 1) * padding, 28 * col + (col - 1) * padding))\n    for i in range(row):\n        for j in range(col):\n            result[i * 28 + (i * padding): i * 28 + (i * padding) + 28,\n                   j * 28 + (j * padding): j * 28 + (j * padding) + 28] = images[i + j * row]\n    return result\n\nclass Encoder(nn.Module):\n    def __init__(self, latent_dimension, hidden_units, data_dimension):\n        super(Encoder, self).__init__()\n        self.fc1 = nn.Linear(data_dimension, hidden_units)\n        self.bn1 = nn.BatchNorm1d(hidden_units)\n        self.fc2_mu = nn.Linear(hidden_units, latent_dimension)\n        self.fc2_sigma = nn.Linear(hidden_units, latent_dimension)\n\n    def forward(self, x):\n        hidden = self.bn1(F.tanh(self.fc1(x)))\n        mu = self.fc2_mu(hidden)\n        log_sigma_square = self.fc2_sigma(hidden)\n        sigma_square = torch.exp(torch.clamp(log_sigma_square, max=10))  # Clamping to avoid overflow\n        return mu, sigma_square\n\nclass Decoder(nn.Module):\n    def __init__(self, latent_dimension, data_dimension, hidden_units=500):\n        super(Decoder, self).__init__()\n        self.fc1_dec = nn.Linear(latent_dimension, hidden_units)\n        self.fc2_dec = nn.Linear(hidden_units, data_dimension)\n\n    def forward(self, z):\n        hidden_dec = F.tanh(self.fc1_dec(z))\n        p = torch.sigmoid(self.fc2_dec(hidden_dec))\n        return p\n\nclass VAE(nn.Module):\n    def __init__(self, args):\n        super(VAE, self).__init__()\n        self.encoder = Encoder(args.latent_dimension, args.hidden_units, args.data_dimension)\n        self.decoder = Decoder(args.latent_dimension, args.data_dimension, args.hidden_units)\n        self.e_path = args.e_path\n        self.d_path = args.d_path\n        if args.resume_training:\n            self.load_state_dict(torch.load(self.e_path))\n\n    @staticmethod\n    def sample_diagonal_gaussian(mu, sigma_square):\n        sigma = torch.sqrt(sigma_square)\n        return mu + torch.randn_like(mu) * sigma\n\n    @staticmethod\n    def sample_Bernoulli(p):\n        return torch.bernoulli(p)\n\n    @staticmethod\n    def logpdf_diagonal_gaussian(z, mu, sigma_square):\n        sigma_square = torch.clamp(sigma_square, min=1e-6)\n        covariance_matrix = torch.diag_embed(sigma_square)\n        dist = MultivariateNormal(mu, covariance_matrix)\n        return dist.log_prob(z)\n\n    @staticmethod\n    def logpdf_bernoulli(x, p):\n        return (x * torch.log(p + 1e-8) + (1 - x) * torch.log(1 - p + 1e-8)).sum(dim=1)\n\n    def elbo_loss(self, sampled_z, mu, sigma_square, x, p):\n        log_q = self.logpdf_diagonal_gaussian(sampled_z, mu, sigma_square)\n        z_mu = torch.zeros_like(mu)\n        z_sigma = torch.ones_like(sigma_square)\n        log_p_z = self.logpdf_diagonal_gaussian(sampled_z, z_mu, z_sigma)\n        log_p = self.logpdf_bernoulli(x, p)\n        return (log_p + log_p_z - log_q).mean()\n\n    def train_model(self, train_loader, val_loader, epochs=200, save_interval=10):\n        optimizer = Adam(self.parameters(), lr=0.001)\n        for epoch in range(epochs):\n            self.train()\n            train_loss = 0\n            for data, _ in train_loader:\n                data = data.view(data.size(0), -1)\n                optimizer.zero_grad()\n                mu, sigma_square = self.encoder(data)\n                zs = self.sample_diagonal_gaussian(mu, sigma_square)\n                p = self.decoder(zs)\n                loss = -self.elbo_loss(zs, mu, sigma_square, data, p)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)\n                optimizer.step()\n                train_loss += loss.item()\n            train_loss /= len(train_loader.dataset)\n            print(f'Epoch {epoch+1}, Average Training Loss: {train_loss:.4f}')\n            if epoch % save_interval == 0:\n                self.evaluate(val_loader)\n                torch.save(self.state_dict(), f'model_epoch_{epoch}.pth')\n\n    def evaluate(self, loader):\n        self.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for data, _ in loader:\n                data = data.view(data.size(0), -1)\n                mu, sigma_square = self.encoder(data)\n                zs = self.sample_diagonal_gaussian(mu, sigma_square)\n                p = self.decoder(zs)\n                loss = -self.elbo_loss(zs, mu, sigma_square, data, p)\n                val_loss += loss.item()\n        val_loss /= len(loader.dataset)\n        print(f'Validation Loss: {val_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:47:38.516345Z","iopub.execute_input":"2024-04-21T08:47:38.516841Z","iopub.status.idle":"2024-04-21T08:47:38.547187Z","shell.execute_reply.started":"2024-04-21T08:47:38.516808Z","shell.execute_reply":"2024-04-21T08:47:38.545545Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=1),  # Convert image to grayscale\n    transforms.Resize((28, 28)),                  # Resize images to 28x28\n    transforms.ToTensor(),                        # Convert images to PyTorch tensors\n    transforms.Normalize((0.5,), (0.5,)),         # Normalize tensors\n    transforms.Lambda(lambda x: x.view(-1))       # Flatten the tensors from [1, 28, 28] to [784]\n])\n\n# Load datasets\ndataset_path = '/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/'\ndataset = datasets.ImageFolder(root=dataset_path, transform=train_transform)\n\n# Split dataset into train and validation sets\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\n# Define DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n\n# Optionally, check the output shape\nimages, labels = next(iter(train_loader))\nprint(\"Image batch shape:\", images.shape)  # Expected output: Image batch shape: [64, 784]\nprint(\"Label batch shape:\", labels.shape)  #\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:29:36.447651Z","iopub.execute_input":"2024-04-21T08:29:36.448131Z","iopub.status.idle":"2024-04-21T08:29:38.847441Z","shell.execute_reply.started":"2024-04-21T08:29:36.448094Z","shell.execute_reply":"2024-04-21T08:29:38.846083Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Image batch shape: torch.Size([64, 784])\nLabel batch shape: torch.Size([64])\n","output_type":"stream"}]},{"cell_type":"code","source":"    def logpdf_diagonal_gaussian(z, mu, sigma_square):\n        # Input:\n        #   z: sample [batch_size x latent_dimension]\n        #   mu: mean of the gaussian distribution [batch_size x latent_dimension]\n        #   sigma_square: variance of the gaussian distribution [batch_size x latent_dimension]\n        # Output:\n        #    logprob: log-probability of a diagomnal gaussian [batch_size]\n        from torch.distributions.multivariate_normal import MultivariateNormal\n        logprob = torch.zeros((mu.shape[0]))\n        for i in range(mu.shape[0]):\n            dist = MultivariateNormal(mu[i], sigma_square[i]*torch.eye((mu.shape[1])))\n            logprob[i] = dist.log_prob(z[i])        \n        return logprob","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:17:09.388900Z","iopub.execute_input":"2024-04-21T08:17:09.389354Z","iopub.status.idle":"2024-04-21T08:17:09.397087Z","shell.execute_reply.started":"2024-04-21T08:17:09.389303Z","shell.execute_reply":"2024-04-21T08:17:09.395560Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import argparse\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=\"VAE Model Configuration\")\n    parser.add_argument('--latent_dimension', type=int, default=2, help='Dimensionality of the latent space')\n    parser.add_argument('--hidden_units', type=int, default=500, help='Number of units in the hidden layer of the encoder and decoder')\n    parser.add_argument('--data_dimension', type=int, default=784, help='Dimensionality of the flattened input images (e.g., 28*28 for MNIST)')\n    parser.add_argument('--batch_size', type=int, default=100, help='Training batch size')\n    parser.add_argument('--num_epochs', type=int, default=200, help='Number of epochs to train')\n    parser.add_argument('--e_path', type=str, default='encoder.pth', help='Path to save the encoder weights')\n    parser.add_argument('--d_path', type=str, default='decoder.pth', help='Path to save the decoder weights')\n    parser.add_argument('--resume_training', type=bool, default=False, help='Flag to determine if training should be resumed from saved model')\n\n    return parser.parse_args(args=[])  # Here, args=[] is used for illustration in notebooks or scripts without command line args\n\nargs = get_args()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:29:42.761596Z","iopub.execute_input":"2024-04-21T08:29:42.762926Z","iopub.status.idle":"2024-04-21T08:29:42.774106Z","shell.execute_reply.started":"2024-04-21T08:29:42.762874Z","shell.execute_reply":"2024-04-21T08:29:42.772406Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"vae_model = VAE(args)  # make sure to define args or pass relevant parameters\nvae_model.train_model(train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:47:43.947719Z","iopub.execute_input":"2024-04-21T08:47:43.948190Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1, Average Training Loss: -18.2412\nValidation Loss: -44.8321\nEpoch 2, Average Training Loss: -68.7700\nEpoch 3, Average Training Loss: -109.8089\nEpoch 4, Average Training Loss: -114.9820\nEpoch 5, Average Training Loss: -118.0587\nEpoch 6, Average Training Loss: -118.9946\nEpoch 7, Average Training Loss: -119.2355\nEpoch 8, Average Training Loss: -119.1165\nEpoch 9, Average Training Loss: -119.1593\nEpoch 10, Average Training Loss: -119.2186\nEpoch 11, Average Training Loss: -119.2931\nValidation Loss: -123.2225\nEpoch 12, Average Training Loss: -119.5014\nEpoch 13, Average Training Loss: -119.4736\nEpoch 14, Average Training Loss: -119.6720\nEpoch 15, Average Training Loss: -119.4730\nEpoch 16, Average Training Loss: -119.6012\nEpoch 17, Average Training Loss: -119.4560\nEpoch 18, Average Training Loss: -119.5685\nEpoch 19, Average Training Loss: -119.5866\nEpoch 20, Average Training Loss: -119.6277\nEpoch 21, Average Training Loss: -119.6319\nValidation Loss: -123.4408\nEpoch 22, Average Training Loss: -119.7288\nEpoch 23, Average Training Loss: -119.6446\nEpoch 24, Average Training Loss: -119.5805\nEpoch 25, Average Training Loss: -119.5952\nEpoch 26, Average Training Loss: -119.7238\nEpoch 27, Average Training Loss: -119.7706\nEpoch 28, Average Training Loss: -119.6346\nEpoch 29, Average Training Loss: -119.8223\nEpoch 30, Average Training Loss: -119.7604\nEpoch 31, Average Training Loss: -119.6736\nValidation Loss: -123.2344\nEpoch 32, Average Training Loss: -119.8569\nEpoch 33, Average Training Loss: -119.7186\nEpoch 34, Average Training Loss: -119.6939\nEpoch 35, Average Training Loss: -119.6357\nEpoch 36, Average Training Loss: -119.8216\nEpoch 37, Average Training Loss: -119.7265\nEpoch 38, Average Training Loss: -119.6399\nEpoch 39, Average Training Loss: -119.7842\nEpoch 40, Average Training Loss: -119.7556\nEpoch 41, Average Training Loss: -119.7581\nValidation Loss: -123.3013\nEpoch 42, Average Training Loss: -119.7309\nEpoch 43, Average Training Loss: -119.8604\nEpoch 44, Average Training Loss: -119.8965\nEpoch 45, Average Training Loss: -119.8391\nEpoch 46, Average Training Loss: -119.7449\nEpoch 47, Average Training Loss: -119.8072\nEpoch 48, Average Training Loss: -119.8832\nEpoch 49, Average Training Loss: -119.8475\nEpoch 50, Average Training Loss: -119.7894\nEpoch 51, Average Training Loss: -119.9507\nValidation Loss: -123.3890\nEpoch 52, Average Training Loss: -119.8329\nEpoch 53, Average Training Loss: -119.9263\nEpoch 54, Average Training Loss: -119.8630\nEpoch 55, Average Training Loss: -119.9698\nEpoch 56, Average Training Loss: -119.9146\nEpoch 57, Average Training Loss: -119.8765\nEpoch 58, Average Training Loss: -119.2141\nEpoch 59, Average Training Loss: -119.9730\nEpoch 60, Average Training Loss: -119.9526\nEpoch 61, Average Training Loss: -119.9764\nValidation Loss: -123.6906\nEpoch 62, Average Training Loss: -119.9158\nEpoch 63, Average Training Loss: -119.9742\nEpoch 64, Average Training Loss: -119.8641\nEpoch 65, Average Training Loss: -119.9608\nEpoch 66, Average Training Loss: -119.9497\nEpoch 67, Average Training Loss: -119.8040\nEpoch 68, Average Training Loss: -119.9200\nEpoch 69, Average Training Loss: -119.7895\nEpoch 70, Average Training Loss: -119.9624\nEpoch 71, Average Training Loss: -119.9193\nValidation Loss: -122.8341\nEpoch 72, Average Training Loss: -119.9746\nEpoch 73, Average Training Loss: -119.9999\nEpoch 74, Average Training Loss: -119.9522\nEpoch 75, Average Training Loss: -119.8715\nEpoch 76, Average Training Loss: -119.9705\nEpoch 77, Average Training Loss: -120.0021\nEpoch 78, Average Training Loss: -120.0552\nEpoch 79, Average Training Loss: -119.9118\nEpoch 80, Average Training Loss: -120.0582\nEpoch 81, Average Training Loss: -120.0310\nValidation Loss: -123.5817\nEpoch 82, Average Training Loss: -119.9482\nEpoch 83, Average Training Loss: -119.9513\nEpoch 84, Average Training Loss: -119.9269\nEpoch 85, Average Training Loss: -120.0419\nEpoch 86, Average Training Loss: -120.0932\nEpoch 87, Average Training Loss: -120.0339\nEpoch 88, Average Training Loss: -120.0245\nEpoch 89, Average Training Loss: -120.0702\nEpoch 90, Average Training Loss: -120.0914\nEpoch 91, Average Training Loss: -120.1003\nValidation Loss: -123.8308\nEpoch 92, Average Training Loss: -120.1560\nEpoch 93, Average Training Loss: -120.0842\nEpoch 94, Average Training Loss: -120.1590\nEpoch 95, Average Training Loss: -120.0784\nEpoch 96, Average Training Loss: -120.1372\nEpoch 97, Average Training Loss: -120.1128\nEpoch 98, Average Training Loss: -120.1728\nEpoch 99, Average Training Loss: -120.1195\nEpoch 100, Average Training Loss: -120.1387\nEpoch 101, Average Training Loss: -120.0950\nValidation Loss: -123.8857\nEpoch 102, Average Training Loss: -120.2325\nEpoch 103, Average Training Loss: -120.1800\nEpoch 104, Average Training Loss: -120.0814\nEpoch 105, Average Training Loss: -120.0532\nEpoch 106, Average Training Loss: -120.1769\nEpoch 107, Average Training Loss: -120.2416\nEpoch 108, Average Training Loss: -120.1454\nEpoch 109, Average Training Loss: -120.1581\nEpoch 110, Average Training Loss: -120.1132\nEpoch 111, Average Training Loss: -120.0765\nValidation Loss: -123.8589\nEpoch 112, Average Training Loss: -120.2231\nEpoch 113, Average Training Loss: -120.3124\nEpoch 114, Average Training Loss: -120.2418\nEpoch 115, Average Training Loss: -120.2159\nEpoch 116, Average Training Loss: -120.1828\nEpoch 117, Average Training Loss: -120.2557\nEpoch 118, Average Training Loss: -120.1050\nEpoch 119, Average Training Loss: -120.2535\nEpoch 120, Average Training Loss: -120.3504\nEpoch 121, Average Training Loss: -120.4193\nValidation Loss: -123.8810\nEpoch 122, Average Training Loss: -120.2608\nEpoch 123, Average Training Loss: -120.2626\nEpoch 124, Average Training Loss: -120.3551\nEpoch 125, Average Training Loss: -120.3425\nEpoch 126, Average Training Loss: -120.3514\nEpoch 127, Average Training Loss: -120.1504\nEpoch 128, Average Training Loss: -120.2725\nEpoch 129, Average Training Loss: -120.1532\nEpoch 130, Average Training Loss: -119.6634\nEpoch 131, Average Training Loss: -120.0984\nValidation Loss: -123.9583\nEpoch 132, Average Training Loss: -120.0593\nEpoch 133, Average Training Loss: -119.9331\nEpoch 134, Average Training Loss: -120.0580\nEpoch 135, Average Training Loss: -119.8247\nEpoch 136, Average Training Loss: -120.1482\nEpoch 137, Average Training Loss: -119.9357\nEpoch 138, Average Training Loss: -120.0744\nEpoch 139, Average Training Loss: -120.1223\nEpoch 140, Average Training Loss: -119.9506\nEpoch 141, Average Training Loss: -119.8506\nValidation Loss: -123.9593\n","output_type":"stream"}]}]}